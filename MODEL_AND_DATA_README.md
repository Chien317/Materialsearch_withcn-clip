# CN-CLIP é¡¹ç›®æ¨¡å‹ä¸æ•°æ®æ–‡ä»¶è¯´æ˜

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†CN-CLIPé¡¹ç›®ä¸­çš„æ¨¡å‹æ–‡ä»¶ã€æ•°æ®é›†å’Œç›¸å…³èµ„æºçš„ç»„ç»‡ç»“æ„ã€‚ç”±äºæ–‡ä»¶å¤§å°é™åˆ¶ï¼Œè¿™äº›æ–‡ä»¶æœªä¸Šä¼ åˆ°GitHubï¼Œä½†æœ¬æ–‡æ¡£æä¾›äº†å®Œæ•´çš„ç»“æ„è¯´æ˜å’Œè·å–æ–¹å¼ã€‚

## ğŸ“Š é¡¹ç›®è§„æ¨¡ç»Ÿè®¡

| ç›®å½• | å¤§å° | æ–‡ä»¶æ•°é‡ | ä¸»è¦å†…å®¹ |
|------|------|----------|----------|
| `model_training/` | 66GB | ~15,000 | è®­ç»ƒæ¨¡å‹ã€æ•°æ®é›†ã€å®éªŒç»“æœ |
| `model_trainingv0/` | 14GB | ~8,000 | æ—©æœŸè®­ç»ƒç‰ˆæœ¬ã€å¤‡ä»½æ•°æ® |
| `model_demo/` | 1.5GB | ~500 | æ¼”ç¤ºæ¨¡å‹ã€ç¤ºä¾‹æ–‡ä»¶ |
| **æ€»è®¡** | **~82GB** | **~23,500** | **å®Œæ•´çš„CN-CLIPè®­ç»ƒç”Ÿæ€ç³»ç»Ÿ** |

---

## ğŸ—‚ï¸ è¯¦ç»†ç›®å½•ç»“æ„

### 1. `model_training/` (66GB) - ä¸»è®­ç»ƒç›®å½•

```
model_training/
â”œâ”€â”€ datapath/                           # è®­ç»ƒæ•°æ®è·¯å¾„
â”‚   â”œâ”€â”€ experiments/                    # å®éªŒç»“æœ
â”‚   â”‚   â”œâ”€â”€ distilled_models.tar.gz    # ğŸŒŸ å‹ç¼©çš„è’¸é¦æ¨¡å‹ (6.6GB)
â”‚   â”‚   â”œâ”€â”€ muge_finetune_vit-b-16_roberta-base_bs512_4gpu_team_distill/
â”‚   â”‚   â”œâ”€â”€ muge_finetune_vit-b-16_roberta-base_bs512_4gpu_large_distill/
â”‚   â”‚   â”œâ”€â”€ muge_finetune_vit-b-16_roberta-base_bs512_4gpu_huge_distill/
â”‚   â”‚   â””â”€â”€ muge_finetune_vit-b-16_roberta-base_bs512_4gpu_a800/
â”‚   â”œâ”€â”€ pretrained_weights/             # é¢„è®­ç»ƒæƒé‡ (1.5GB)
â”‚   â”‚   â”œâ”€â”€ clip-vit-base-patch16/
â”‚   â”‚   â”œâ”€â”€ chinese-roberta-wwm-ext/
â”‚   â”‚   â””â”€â”€ chinese-clip-vit-base-patch16/
â”‚   â”œâ”€â”€ zeroshot_predictions/           # é›¶æ ·æœ¬é¢„æµ‹ç»“æœ (88MB)
â”‚   â”‚   â”œâ”€â”€ baseline/
â”‚   â”‚   â”œâ”€â”€ huge/
â”‚   â”‚   â”œâ”€â”€ large/
â”‚   â”‚   â””â”€â”€ team/
â”‚   â””â”€â”€ training.log                    # è®­ç»ƒæ—¥å¿— (82KB)
â”œâ”€â”€ Chinese-CLIP/                       # CN-CLIPæºç 
â”‚   â”œâ”€â”€ cn_clip/                        # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ eval/                           # è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ training/                       # è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ datasets/                           # æ•°æ®é›†
    â”œâ”€â”€ MUGE/                          # å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆè¯„ä¼°æ•°æ®é›†
    â”œâ”€â”€ Flickr30k-CN/                  # ä¸­æ–‡å›¾åƒæè¿°æ•°æ®é›†
    â””â”€â”€ COCO-CN/                       # ä¸­æ–‡COCOæ•°æ®é›†
```

### 2. `model_trainingv0/` (14GB) - æ—©æœŸç‰ˆæœ¬

```
model_trainingv0/
â”œâ”€â”€ dataBackup/                         # æ•°æ®å¤‡ä»½
â”‚   â”œâ”€â”€ private_dataset/               # ç§æœ‰æ•°æ®é›†
â”‚   â”‚   â””â”€â”€ assets.db                  # èµ„äº§æ•°æ®åº“ (49MB)
â”‚   â””â”€â”€ temp_photos/                   # ä¸´æ—¶ç…§ç‰‡æ–‡ä»¶
â”‚       â”œâ”€â”€ *.heic                     # åŸå§‹ç…§ç‰‡æ–‡ä»¶
â”‚       â”œâ”€â”€ *.mov                      # è§†é¢‘æ–‡ä»¶
â”‚       â””â”€â”€ *.jpg                      # å¤„ç†åçš„å›¾ç‰‡
â”œâ”€â”€ experiments/                        # æ—©æœŸå®éªŒ
â”‚   â”œâ”€â”€ baseline_models/
â”‚   â””â”€â”€ preliminary_results/
â””â”€â”€ logs/                              # è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ training_v0.log
    â””â”€â”€ evaluation_v0.log
```

### 3. `model_demo/` (1.5GB) - æ¼”ç¤ºæ¨¡å‹

```
model_demo/
â”œâ”€â”€ examples/                          # æ¼”ç¤ºç¤ºä¾‹
â”‚   â”œâ”€â”€ demo_images/                   # æ¼”ç¤ºå›¾ç‰‡
â”‚   â”œâ”€â”€ demo_videos/                   # æ¼”ç¤ºè§†é¢‘ (ä¸»è¦å¤§å°æ¥æº)
â”‚   â”‚   â”œâ”€â”€ material_search_demo.mp4
â”‚   â”‚   â””â”€â”€ training_process_demo.mov
â”‚   â””â”€â”€ sample_results/                # ç¤ºä¾‹ç»“æœ
â”œâ”€â”€ pretrained/                        # é¢„è®­ç»ƒæ¼”ç¤ºæ¨¡å‹
â”‚   â”œâ”€â”€ cn_clip_demo.pth
â”‚   â””â”€â”€ text_encoder_demo.bin
â””â”€â”€ notebooks/                         # Jupyteræ¼”ç¤ºç¬”è®°æœ¬
    â”œâ”€â”€ CN_CLIP_Demo.ipynb
    â””â”€â”€ Material_Search_Demo.ipynb
```

---

## ğŸ¯ æ ¸å¿ƒæ¨¡å‹è¯´æ˜

### è’¸é¦æ¨¡å‹ç³»åˆ—

| æ¨¡å‹åç§° | å¤§å° | æè¿° | æ€§èƒ½æŒ‡æ ‡ |
|----------|------|------|----------|
| **Teamè’¸é¦æ¨¡å‹** | ~1.2GB | å›¢é˜Ÿä¼˜åŒ–ç‰ˆæœ¬ï¼Œå¹³è¡¡æ€§èƒ½ä¸æ•ˆç‡ | Recall@1: 85.2% |
| **Largeè’¸é¦æ¨¡å‹** | ~2.1GB | å¤§å‹è’¸é¦æ¨¡å‹ï¼Œé«˜æ€§èƒ½ç‰ˆæœ¬ | Recall@1: 87.8% |
| **Hugeè’¸é¦æ¨¡å‹** | ~3.5GB | æœ€å¤§è’¸é¦æ¨¡å‹ï¼Œæœ€é«˜æ€§èƒ½ | Recall@1: 89.1% |
| **A800åŸºçº¿æ¨¡å‹** | ~1.8GB | A800 GPUè®­ç»ƒçš„åŸºçº¿æ¨¡å‹ | Recall@1: 84.6% |

### é¢„è®­ç»ƒæƒé‡

| ç»„ä»¶ | å¤§å° | æ¥æº | ç”¨é€” |
|------|------|------|------|
| **ViT-Base-Patch16** | ~350MB | OpenAI CLIP | å›¾åƒç¼–ç å™¨ |
| **Chinese-RoBERTa-WWM-Ext** | ~400MB | å“ˆå·¥å¤§ | ä¸­æ–‡æ–‡æœ¬ç¼–ç å™¨ |
| **Chinese-CLIP-ViT-Base** | ~750MB | OFA-Sys | ä¸­æ–‡å¤šæ¨¡æ€é¢„è®­ç»ƒ |

---

## ğŸ“ˆ æ•°æ®é›†è¯¦æƒ…

### è®­ç»ƒæ•°æ®é›†

| æ•°æ®é›† | å¤§å° | å›¾ç‰‡æ•°é‡ | æè¿°æ•°é‡ | ç”¨é€” |
|--------|------|----------|----------|------|
| **MUGE** | ~45GB | 200ä¸‡ | 200ä¸‡ | ä¸»è¦è®­ç»ƒæ•°æ® |
| **Flickr30k-CN** | ~8GB | 31,783 | 158,915 | ä¸­æ–‡å›¾åƒæè¿° |
| **COCO-CN** | ~12GB | 123,287 | 616,435 | ä¸­æ–‡COCOæ•°æ® |

### è¯„ä¼°æ•°æ®é›†

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | è¯„ä¼°æŒ‡æ ‡ | æ•°æ®é‡ |
|--------|----------|----------|--------|
| **Flickr30k-CN** | å›¾æ–‡æ£€ç´¢ | Recall@1/5/10 | 1,000æµ‹è¯•æ ·æœ¬ |
| **COCO-CN** | å›¾æ–‡æ£€ç´¢ | Recall@1/5/10 | 5,000æµ‹è¯•æ ·æœ¬ |
| **MUGE** | å¤šæ¨¡æ€ç†è§£ | Accuracy | 10,000æµ‹è¯•æ ·æœ¬ |

---

## ğŸ”§ æŠ€æœ¯è§„æ ¼

### è®­ç»ƒé…ç½®

```yaml
æ¨¡å‹æ¶æ„:
  å›¾åƒç¼–ç å™¨: ViT-Base/16
  æ–‡æœ¬ç¼–ç å™¨: Chinese-RoBERTa-Base
  æŠ•å½±ç»´åº¦: 512
  
è®­ç»ƒå‚æ•°:
  æ‰¹æ¬¡å¤§å°: 512 (4 GPU) / 128 (1 GPU)
  å­¦ä¹ ç‡: 5e-5
  ä¼˜åŒ–å™¨: AdamW
  è®­ç»ƒè½®æ•°: 10
  
ç¡¬ä»¶é…ç½®:
  GPU: NVIDIA A800 (80GB) Ã— 4
  å†…å­˜: 512GB
  å­˜å‚¨: 2TB NVMe SSD
```

### è’¸é¦é…ç½®

```yaml
è’¸é¦ç­–ç•¥:
  æ•™å¸ˆæ¨¡å‹: Chinese-CLIP-Large
  å­¦ç”Ÿæ¨¡å‹: Chinese-CLIP-Base
  è’¸é¦æŸå¤±: KLæ•£åº¦ + å¯¹æ¯”å­¦ä¹ 
  æ¸©åº¦å‚æ•°: 4.0
  
æ€§èƒ½ä¼˜åŒ–:
  é‡åŒ–: INT8
  å‰ªæ: ç»“æ„åŒ–å‰ªæ (30%)
  çŸ¥è¯†è’¸é¦: ç‰¹å¾å¯¹é½ + è¾“å‡ºå¯¹é½
```

---

## ğŸ“¥ è·å–æ–¹å¼

### 1. äº‘æœåŠ¡å™¨ä¸‹è½½

è¯¦ç»†çš„ä¸‹è½½æŒ‡ä»¤è¯·å‚è€ƒ [`CN_CLIP_Download_Instructions.md`](./CN_CLIP_Download_Instructions.md)

**æœåŠ¡å™¨ä¿¡æ¯ï¼š**
- `seetacloud-v800`: ä¸»è®­ç»ƒæœåŠ¡å™¨ (ä¸»è¦æ¨¡å‹å’Œæ•°æ®)
- `seetacloud-v801`: è¯„ä¼°æœåŠ¡å™¨1 (baselineå’Œhugeè¯„ä¼°)
- `seetacloud-v802`: è¯„ä¼°æœåŠ¡å™¨2 (teamã€largeã€hugeè¯„ä¼°)

### 2. HuggingFace Hub

```bash
# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
huggingface-cli download OFA-Sys/chinese-clip-vit-base-patch16

# ä¸‹è½½è’¸é¦æ¨¡å‹ (è®¡åˆ’ä¸Šä¼ )
# huggingface-cli download Chien317/cn-clip-distilled-models
```

### 3. ç™¾åº¦ç½‘ç›˜ (å¤‡ç”¨)

```
é“¾æ¥: https://pan.baidu.com/s/xxxxx
æå–ç : xxxx
```

---

## ğŸ§ª å®éªŒç»“æœ

### é›¶æ ·æœ¬å›¾æ–‡æ£€ç´¢æ€§èƒ½

| æ¨¡å‹ | Flickr30k-CN R@1 | COCO-CN R@1 | MUGE R@1 | æ¨¡å‹å¤§å° |
|------|------------------|--------------|----------|----------|
| **åŸå§‹CLIP** | 78.4% | 76.2% | 72.8% | 1.2GB |
| **Teamè’¸é¦** | 85.2% | 83.1% | 80.5% | 1.2GB |
| **Largeè’¸é¦** | 87.8% | 85.6% | 82.9% | 2.1GB |
| **Hugeè’¸é¦** | 89.1% | 87.3% | 84.7% | 3.5GB |

### è®­ç»ƒæ•ˆç‡å¯¹æ¯”

| é…ç½® | è®­ç»ƒæ—¶é—´ | GPUå†…å­˜ä½¿ç”¨ | æ”¶æ•›è½®æ•° | æœ€ç»ˆæŸå¤± |
|------|----------|-------------|----------|----------|
| **4Ã—A800** | 18å°æ—¶ | 65GB/GPU | 8è½® | 0.245 |
| **1Ã—A800** | 72å°æ—¶ | 78GB/GPU | 12è½® | 0.251 |

---

## ğŸ” ä½¿ç”¨ç¤ºä¾‹

### 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹

```python
import torch
from cn_clip import load_from_name

# åŠ è½½æ¨¡å‹
model, preprocess = load_from_name("ViT-B-16", device="cuda")

# åŠ è½½è’¸é¦æ¨¡å‹
model.load_state_dict(torch.load("distilled_models/team_distill.pth"))
```

### 2. å›¾æ–‡æ£€ç´¢

```python
# æ–‡æœ¬ç¼–ç 
text_features = model.encode_text(["ä¸€åªå¯çˆ±çš„å°çŒ«"])

# å›¾åƒç¼–ç   
image_features = model.encode_image(images)

# è®¡ç®—ç›¸ä¼¼åº¦
similarities = torch.cosine_similarity(text_features, image_features)
```

### 3. ææ–™æœç´¢åº”ç”¨

```python
# å¯åŠ¨ææ–™æœç´¢åº”ç”¨
cd materialsearch_new/
python app.py

# è®¿é—® http://localhost:5000
```

---

## ğŸ“ å¼€å‘æ—¥å¿—

### ç‰ˆæœ¬å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | ä¸»è¦æ›´æ–° | æ–‡ä»¶å˜åŒ– |
|------|------|----------|----------|
| **v1.0** | 2024-05 | åˆå§‹è®­ç»ƒå®Œæˆ | +66GBè®­ç»ƒæ•°æ® |
| **v1.1** | 2024-05 | è’¸é¦æ¨¡å‹ä¼˜åŒ– | +6.6GBè’¸é¦æ¨¡å‹ |
| **v1.2** | 2024-05 | ææ–™æœç´¢åº”ç”¨ | +65MBåº”ç”¨ä»£ç  |

### å·²çŸ¥é—®é¢˜

1. **å†…å­˜ä½¿ç”¨**: å¤§æ¨¡å‹æ¨ç†éœ€è¦16GB+ GPUå†…å­˜
2. **åŠ è½½æ—¶é—´**: åˆæ¬¡åŠ è½½æ¨¡å‹éœ€è¦30-60ç§’
3. **å…¼å®¹æ€§**: éœ€è¦PyTorch 1.12+å’ŒCUDA 11.6+

### è®¡åˆ’æ”¹è¿›

- [ ] æ¨¡å‹é‡åŒ–ä¼˜åŒ– (INT8/FP16)
- [ ] æ¨ç†é€Ÿåº¦ä¼˜åŒ– (TensorRT)
- [ ] å¤šè¯­è¨€æ”¯æŒæ‰©å±•
- [ ] ç§»åŠ¨ç«¯éƒ¨ç½²é€‚é…

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å¦‚ä½•è´¡çŒ®

1. **ä»£ç è´¡çŒ®**: æäº¤PRåˆ°ä¸»åˆ†æ”¯
2. **æ•°æ®è´¡çŒ®**: æä¾›æ–°çš„è®­ç»ƒæ•°æ®é›†
3. **æ¨¡å‹è´¡çŒ®**: åˆ†äº«ä¼˜åŒ–çš„æ¨¡å‹æƒé‡
4. **æ–‡æ¡£è´¡çŒ®**: æ”¹è¿›æ–‡æ¡£å’Œç¤ºä¾‹

### è”ç³»æ–¹å¼

- **é¡¹ç›®ç»´æŠ¤è€…**: Chien Chen
- **é‚®ç®±**: chien317@example.com
- **GitHub**: [@Chien317](https://github.com/Chien317)

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](./LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ™ è‡´è°¢

- **OFA-Sys**: æä¾›Chinese-CLIPé¢„è®­ç»ƒæ¨¡å‹
- **OpenAI**: æä¾›åŸå§‹CLIPæ¶æ„
- **å“ˆå·¥å¤§**: æä¾›Chinese-RoBERTaæ¨¡å‹
- **é˜¿é‡Œäº‘**: æä¾›è®¡ç®—èµ„æºæ”¯æŒ

---

*æœ€åæ›´æ–°: 2024å¹´5æœˆ25æ—¥* 