# 分布式零样本图像分类指南

基于Chinese-CLIP蒸馏模型的分布式零样本图像分类完整解决方案

## 📋 概述

本项目基于Chinese-CLIP官方的零样本分类功能，结合我们训练好的蒸馏模型，实现对ELEVATER数据集的大规模分布式零样本图像分类评估。支持多种蒸馏模型类型、20个图像分类数据集，并可在多台GPU服务器上并行执行。

### 🌟 核心特性

- **分布式架构**: 支持多台服务器协同工作
- **自动任务分配**: 智能分配数据集和模型组合任务
- **断点续传**: 支持任务中断后继续执行
- **自动修复**: 内置PyTorch和NumPy兼容性修复
- **实时监控**: 进度跟踪和结果收集

## 🏗️ 系统架构

### 服务器角色分配

| 服务器 | 角色 | 硬件配置 | 主要任务 |
|--------|------|----------|----------|
| `seetacloud-v800` | Master/Coordinator | 4×A800 GPU | team、large模型测试 + 协调管理 |
| `seetacloud-v801` | Worker-1 | 4×A800 GPU | huge、baseline模型测试 |
| `seetacloud-v802` | Worker-2 | 4×GPU + 大存储 | 全模型测试 + 数据源 |

### 核心脚本架构

```
分布式系统核心脚本
├── start_distributed_setup.sh          # 总体搭建向导
├── setup_distributed_wrapper.sh        # 环境设置封装器
├── distributed_coordinator.sh          # 分布式协调器
├── run_zeroshot_classification.sh       # 单任务执行脚本
├── smart_data_distributor.sh           # 数据分发器
├── distilled_model_distributor.sh      # 模型分发器
└── 修复脚本
    ├── fix_all_servers_torch_distributed.sh
    └── fix_numpy_batch.sh
```

## 🚀 快速开始

### 前置条件

1. **SSH无密钥配置**: 确保可以无密钥登录所有云服务器
   ```bash
   ssh seetacloud-v800  # 主服务器
   ssh seetacloud-v801  # 工作节点1
   ssh seetacloud-v802  # 工作节点2
   ```

2. **已训练模型**: 各种蒸馏模型已完成训练
3. **Chinese-CLIP代码库**: 已部署在所有服务器
4. **Conda环境**: `training` 环境已在所有服务器配置

### 一键启动分布式系统

```bash
# 执行完整的分布式环境搭建
./start_distributed_setup.sh
```

这个向导将引导你完成：
1. SSH配置验证
2. 分布式环境设置
3. 数据和模型分发
4. 单卡测试验证
5. 多卡模式切换

### 快速测试单个任务

```bash
# 测试特定数据集和模型
echo "y" | ./run_zeroshot_classification.sh "cifar-10" "baseline" 0 32 "v801"
```

### 启动完整分布式测试

```bash
# 启动分布式协调器，自动分配和执行所有任务
./distributed_coordinator.sh
```

## 📊 支持的数据集和模型

### ELEVATER数据集 (20个)

| 数据集名称 | 类别数 | 大小 | 描述 |
|-----------|--------|------|------|
| `cifar-10` | 10 | 小 | CIFAR-10图像分类 |
| `cifar-100` | 100 | 小 | CIFAR-100图像分类 |
| `caltech-101` | 101 | 中 | Caltech-101物体识别 |
| `oxford-flower-102` | 102 | 中 | 牛津花卉数据集 |
| `food-101` | 101 | 中 | 食物分类数据集 |
| `fgvc-aircraft-2013b-variants102` | 102 | 中 | 飞机型号分类 |
| `eurosat_clip` | 10 | 小 | 欧洲卫星图像分类 |
| `resisc45_clip` | 45 | 大 | 遥感图像场景分类 |
| `country211` | 211 | **超大** | 国家地理位置分类 (9GB) |
| `mnist` | 10 | 极小 | 手写数字识别 |
| `stl10` | 10 | 小 | STL-10图像分类 |
| `svhn` | 10 | 小 | 街景门牌号数字 |
| `pcam` | 2 | 中 | 病理图像分类 |
| `rendered-sst2` | 2 | 小 | 渲染文本情感分析 |
| `pets` | 37 | 中 | 宠物品种分类 |
| `cars` | 196 | 中 | 汽车型号分类 |
| `dtd` | 47 | 小 | 纹理描述数据集 |
| `sun397` | 397 | 大 | 场景理解数据集 |
| `gtsrb` | 43 | 中 | 德国交通标志识别 |
| `kitti-distance` | 4 | 中 | KITTI距离估计 |

### 蒸馏模型类型

| 模型类型 | 描述 | 实际模型路径 |
|---------|------|-------------|
| `team` | TEAM蒸馏模型 | `muge_finetune_vit-b-16_roberta-base_bs512_4gpu_team_distill` |
| `large` | Large蒸馏模型 | `muge_finetune_vit-b-16_roberta-base_bs512_4gpu_large_distill` |
| `huge` | Huge蒸馏模型 | `muge_finetune_vit-b-16_roberta-base_bs512_4gpu_huge_distill` |
| `baseline` | 基准对比模型 | `muge_finetune_vit-b-16_roberta-base_bs512_4gpu_a800` |

## 🔧 核心脚本详解

### 1. 分布式协调器 (`distributed_coordinator.sh`)

**功能**: 
- 自动任务分配和调度
- 实时进度监控
- 结果收集和汇总
- 断点续传支持

**任务分配策略**:
```
v800 (12任务): team + large 模型 × 前6个数据集
v801 (12任务): huge + baseline 模型 × 前6个数据集  
v802 (12任务): 所有模型 × 后3个数据集 (包括超大数据集)
```

**使用方法**:
```bash
./distributed_coordinator.sh
```

### 2. 单任务执行器 (`run_zeroshot_classification.sh`)

**功能**:
- 执行单个数据集+模型组合的零样本分类
- 支持交互式参数选择
- 自动服务器选择和SSH连接
- 结果自动保存

**参数格式**:
```bash
./run_zeroshot_classification.sh <数据集> <模型> [GPU_ID] [batch_size] [服务器]
```

**示例**:
```bash
# 完整参数模式
./run_zeroshot_classification.sh "cifar-100" "team" 0 64 "v800"

# 交互式模式
./run_zeroshot_classification.sh "cifar-100"

# 自动确认模式  
echo "y" | ./run_zeroshot_classification.sh "cifar-10" "baseline" 0 32 "v801"
```

### 3. 环境设置封装器 (`setup_distributed_wrapper.sh`)

**功能**:
- 批量上传环境设置脚本到各服务器
- 远程执行环境配置
- 验证配置结果
- 生成详细日志

**自动处理**:
- SSH连通性检查
- 脚本上传和权限设置
- Conda环境验证
- Chinese-CLIP代码库检查

### 4. 数据和模型分发器

**数据分发器** (`smart_data_distributor.sh`):
- 从v802自动分发ELEVATER数据集到其他服务器
- 智能检测已存在数据，避免重复传输
- 特别处理v801数据写入问题

**模型分发器** (`distilled_model_distributor.sh`):
- 从v800分发训练好的蒸馏模型
- 验证模型文件完整性
- 自动处理checkpoint文件

## 🛠️ 兼容性修复

### 1. PyTorch分布式修复 (`fix_all_servers_torch_distributed.sh`)

**修复问题**: 
- PyTorch 1.12.0+cu113版本的`torch.distributed.nn`模块缺失
- `python3 -m torch.distributed.launch`已弃用

**修复内容**:
```bash
# 1. 替换启动方式
python3 -m torch.distributed.launch → torchrun

# 2. 添加兼容性代码
try:
    import torch.distributed.nn
except (ImportError, ModuleNotFoundError):
    # 创建虚拟模块
    import torch.distributed
    import types
    nn_module = types.ModuleType('torch.distributed.nn')
    nn_module.all_gather = torch.distributed.all_gather
    torch.distributed.nn = nn_module
```

**执行方法**:
```bash
./fix_all_servers_torch_distributed.sh
```

### 2. NumPy兼容性修复 (`fix_numpy_batch.sh`)

**修复问题**: 
- NumPy 1.25+版本中标量转换的警告

**修复内容**:
```python
# 修复前 (产生警告)
float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy())

# 修复后 (兼容新版本)
correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy().item()
```

**执行方法**:
```bash
./fix_numpy_batch.sh
```

## 📈 分布式测试流程

### 完整流程

1. **环境准备**
   ```bash
   ./start_distributed_setup.sh
   ```

2. **修复兼容性问题**
   ```bash
   ./fix_all_servers_torch_distributed.sh
   ./fix_numpy_batch.sh
   ```

3. **启动分布式测试**
   ```bash
   ./distributed_coordinator.sh
   ```

4. **监控进度**
   - 实时日志: `./distributed_results_<timestamp>/coordinator.log`
   - 各服务器状态: SSH到服务器查看GPU使用情况

5. **收集结果**
   - 自动生成最终报告: `./distributed_results_<timestamp>/final_report.txt`
   - 详细结果文件在各服务器的`/root/autodl-tmp/datapath/zeroshot_predictions/`

### 断点续传

如果测试中断，重新运行协调器会自动检测：

```bash
🔍 发现未完成的分布式测试: distributed_results_20240524_143022
📊 检查进度状态...
✅ 发现 18 个已完成的任务 (总共 36 个)
🚀 是否继续未完成的测试？(y/N):
```

## 📊 结果分析

### 输出文件结构

```
distributed_results_<timestamp>/
├── coordinator.log              # 主协调器日志
├── progress.json               # 进度跟踪
├── final_report.txt           # 最终测试报告
├── tasks/                     # 任务分配
│   ├── seetacloud-v800.tasks
│   ├── seetacloud-v801.tasks
│   └── seetacloud-v802.tasks
├── logs/                      # 各服务器日志
└── results/                   # 收集的结果文件
```

### 结果格式

每个任务生成JSON格式结果：
```json
{
    "model_name": "CN-CLIP-ViT-B-16",
    "dataset_name": "cifar-100", 
    "num_trainable_params": 0,
    "num_params": 188262913,
    "n_shot": 0,
    "rnd_seeds": [123],
    "predictions": "预测概率矩阵 [1, 样本数, 类别数]"
}
```

### 性能指标

控制台输出示例：
```
Result:
zeroshot-top1: 0.6444

[统计] 任务完成情况:
  ✅ seetacloud-v800: 12/12 任务完成
  ✅ seetacloud-v801: 12/12 任务完成  
  ✅ seetacloud-v802: 12/12 任务完成
  📊 总体进度: 36/36 (100%)
```

## ⚠️ 注意事项和故障排除

### 常见问题

1. **v801数据写入异常**
   - 症状: 数据分发到v801失败或容量显示异常
   - 解决: 检查磁盘挂载状态，重新分发数据

2. **baseline模型路径错误**
   - 症状: baseline任务全部失败
   - 解决: 检查模型路径配置，确保指向正确的a800模型

3. **SSH连接超时**
   - 症状: 分布式协调器无法连接某些服务器
   - 解决: 检查网络连接，重启SSH服务

4. **GPU内存不足**
   - 症状: 大数据集测试时出现OOM错误
   - 解决: 减少batch_size或使用更少GPU

### 性能优化建议

1. **批处理大小调整**
   ```bash
   # 小数据集使用较大batch_size
   ./run_zeroshot_classification.sh "cifar-10" "team" 0 64 "v800"
   
   # 大数据集使用较小batch_size  
   ./run_zeroshot_classification.sh "country211" "huge" 0 16 "v802"
   ```

2. **服务器选择策略**
   - 大数据集优先分配给v802 (大存储)
   - 计算密集型任务分配给v800/v801 (A800 GPU)
   - baseline模型测试优先使用v800 (有完整模型)

3. **网络优化**
   - 大文件传输使用rsync而非scp
   - 启用SSH连接复用
   - 使用screen/tmux避免网络中断影响

### 监控和调试

1. **实时监控GPU使用**
   ```bash
   # 监控所有服务器GPU状态
   for server in v800 v801 v802; do
     echo "=== $server ==="
     ssh seetacloud-$server "nvidia-smi"
   done
   ```

2. **检查任务进度**
   ```bash
   # 查看当前完成的任务数
   find ./distributed_results_*/results -name "*.json" | wc -l
   ```

3. **日志分析**
   ```bash
   # 查看主协调器日志
   tail -f distributed_results_*/coordinator.log
   
   # 查看特定服务器执行日志
   ssh seetacloud-v801 "tail -f /tmp/zeroshot_evaluation.log"
   ```

## 🎯 最佳实践

1. **首次部署**: 使用`start_distributed_setup.sh`完成完整环境搭建
2. **定期测试**: 定期执行单卡测试验证环境状态
3. **结果备份**: 及时备份重要的测试结果和模型文件
4. **资源监控**: 监控磁盘空间和GPU使用情况
5. **分阶段执行**: 大规模测试建议分批进行，避免资源耗尽

---

*基于Chinese-CLIP官方框架，结合蒸馏模型训练成果，实现高效的分布式零样本图像分类评估系统。* 