#!/bin/bash

echo "=================================================="
echo "  å…¨åŠŸèƒ½GPUé…ç½®æ£€æµ‹å·¥å…· (å¢å¼ºç‰ˆ)"
echo "=================================================="
echo "ğŸ¯ ç›®æ ‡: è‡ªåŠ¨é€‚é…å¼‚æ„å¤šæœºå¤šå¡ç¯å¢ƒ + è¯¦ç»†ç¡¬ä»¶æ£€æµ‹"
echo ""

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# æœåŠ¡å™¨åˆ—è¡¨
servers="seetacloud-v800 seetacloud-v801 seetacloud-v802"

# è¯¦ç»†æ£€æµ‹å‡½æ•°
detailed_gpu_check() {
    local server=$1
    echo "  ğŸ” è¯¦ç»†æ£€æµ‹ $server GPUç¯å¢ƒ..."
    
    ssh "$server" << 'EOF'
        echo "    ğŸ“Š GPUç¡¬ä»¶ä¿¡æ¯:"
        nvidia-smi --query-gpu=index,name,memory.total,memory.used,memory.free --format=csv,noheader,nounits | while read line; do
            echo "      GPU $line"
        done
        
        echo ""
        echo "    ğŸ”§ CUDAç¯å¢ƒ:"
        nvcc_version=$(nvcc --version 2>/dev/null | grep "release" | sed 's/.*release \([0-9.]*\).*/\1/' || echo "æœªå®‰è£…")
        echo "      CUDAç‰ˆæœ¬: $nvcc_version"
        
        echo ""
        echo "    ğŸ PyTorchç¯å¢ƒ:"
        python -c "
import torch
print(f'      PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'      CUDAå¯ç”¨: {torch.cuda.is_available()}')
print(f'      cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else \"æœªå®‰è£…\"}')

# æ£€æŸ¥åˆ†å¸ƒå¼æ”¯æŒ
try:
    import torch.distributed as dist
    print(f'      NCCLå¯ç”¨: {dist.is_nccl_available()}')
    print(f'      MPIå¯ç”¨: {dist.is_mpi_available()}')
except ImportError:
    print('      åˆ†å¸ƒå¼æ”¯æŒ: æœªå®‰è£…')

# æµ‹è¯•å¤šGPUé€šä¿¡
if torch.cuda.device_count() >= 2:
    try:
        device_0 = torch.device('cuda:0')
        device_1 = torch.device('cuda:1')
        x = torch.randn(2, 2, device=device_0)
        y = x.to(device_1)
        print('      å¤šGPUé€šä¿¡: âœ… æ­£å¸¸')
    except Exception as e:
        print(f'      å¤šGPUé€šä¿¡: âŒ å¤±è´¥ ({str(e)[:50]}...)')
else:
    print('      å¤šGPUé€šä¿¡: âš ï¸ GPUæ•°é‡ä¸è¶³')
" 2>/dev/null || echo "      Pythonç¯å¢ƒæ£€æµ‹å¤±è´¥"
EOF
}

echo "ğŸ” æ£€æµ‹å„æœåŠ¡å™¨GPUæ•°é‡å’Œè¯¦ç»†ä¿¡æ¯..."
echo "----------------------------------------------"

total_gpus=0

# ä½¿ç”¨æ™®é€šå˜é‡ä»£æ›¿å…³è”æ•°ç»„
v800_gpus=0
v801_gpus=0
v802_gpus=0

for server in $servers; do
    echo "ğŸ“¡ æ£€æµ‹ $server..."
    
    # æ£€æµ‹GPUæ•°é‡
    gpu_count=$(ssh "$server" "source /root/miniconda3/etc/profile.d/conda.sh && conda activate training && python -c 'import torch; print(torch.cuda.device_count())'" 2>/dev/null)
    
    if [ $? -eq 0 ] && [ -n "$gpu_count" ] && [ "$gpu_count" -gt 0 ]; then
        # æ ¹æ®æœåŠ¡å™¨åè®¾ç½®å¯¹åº”å˜é‡
        case "$server" in
            "seetacloud-v800")
                v800_gpus=$gpu_count
                ;;
            "seetacloud-v801")
                v801_gpus=$gpu_count
                ;;
            "seetacloud-v802")
                v802_gpus=$gpu_count
                ;;
        esac
        
        total_gpus=$((total_gpus + gpu_count))
        echo "  âœ… $server: $gpu_count GPU(s)"
        
        # æ‰§è¡Œè¯¦ç»†æ£€æµ‹
        detailed_gpu_check "$server"
        
    else
        echo "  âŒ $server: æ— æ³•è¿æ¥æˆ–æ£€æµ‹å¤±è´¥"
    fi
    echo ""
done

echo ""
echo "ğŸ“Š **GPUé…ç½®æ€»ç»“**"
echo "----------------------------------------------"

# æ˜¾ç¤ºæ¯ä¸ªæœåŠ¡å™¨çš„çŠ¶æ€
if [ "$v800_gpus" -gt 0 ]; then
    echo -e "  ${GREEN}seetacloud-v800: $v800_gpus GPU(s)${NC}"
else
    echo -e "  ${RED}seetacloud-v800: ä¸å¯ç”¨${NC}"
fi

if [ "$v801_gpus" -gt 0 ]; then
    echo -e "  ${GREEN}seetacloud-v801: $v801_gpus GPU(s)${NC}"
else
    echo -e "  ${RED}seetacloud-v801: ä¸å¯ç”¨${NC}"
fi

if [ "$v802_gpus" -gt 0 ]; then
    echo -e "  ${GREEN}seetacloud-v802: $v802_gpus GPU(s)${NC}"
else
    echo -e "  ${RED}seetacloud-v802: ä¸å¯ç”¨${NC}"
fi

echo ""
echo -e "${BLUE}æ€»GPUæ•°é‡: $total_gpus${NC}"

# ç”ŸæˆåŠ¨æ€é…ç½®
cat > dynamic_gpu_config.env << EOF
# åŠ¨æ€GPUé…ç½® - $(date)
TOTAL_GPUS=$total_gpus
v800_GPUS=$v800_gpus
v801_GPUS=$v801_gpus
v802_GPUS=$v802_gpus
EOF

echo ""
echo "ğŸ“ **åˆ†å¸ƒå¼è®­ç»ƒé…ç½®å»ºè®®**"
echo "----------------------------------------------"

if [ "$total_gpus" -gt 0 ]; then
    echo -e "${GREEN}âœ… å¯ä»¥å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ${NC}"
    echo ""
    echo "ğŸš€ **torchrunå‘½ä»¤ç¤ºä¾‹**:"
    echo "torchrun \\"
    echo "  --nnodes=3 \\"
    echo "  --nproc_per_node=\$LOCAL_GPU_COUNT \\"
    echo "  --rdzv_id=123 \\"
    echo "  --rdzv_backend=c10d \\"
    echo "  --rdzv_endpoint=seetacloud-v800:23456 \\"
    echo "  train.py"
    echo ""
    echo "ğŸ’¡ **å¼‚æ„é…ç½®è¯´æ˜**:"
    echo "  - v800èŠ‚ç‚¹: $v800_gpus GPU(s) (ä¸»èŠ‚ç‚¹)"
    echo "  - v801èŠ‚ç‚¹: $v801_gpus GPU(s)"
    echo "  - v802èŠ‚ç‚¹: $v802_gpus GPU(s)"
    echo "  - æ€»è®¡ç®—èƒ½åŠ›: $total_gpus GPU(s)"
    echo ""
    echo "âš–ï¸ **è´Ÿè½½åˆ†é…**:"
    
    if [ "$v800_gpus" -gt 0 ]; then
        percentage=$(echo "scale=1; $v800_gpus * 100 / $total_gpus" | bc -l 2>/dev/null || echo "æœªçŸ¥")
        echo "  - seetacloud-v800: ${percentage}% è®¡ç®—è´Ÿè½½"
    fi
    
    if [ "$v801_gpus" -gt 0 ]; then
        percentage=$(echo "scale=1; $v801_gpus * 100 / $total_gpus" | bc -l 2>/dev/null || echo "æœªçŸ¥")
        echo "  - seetacloud-v801: ${percentage}% è®¡ç®—è´Ÿè½½"
    fi
    
    if [ "$v802_gpus" -gt 0 ]; then
        percentage=$(echo "scale=1; $v802_gpus * 100 / $total_gpus" | bc -l 2>/dev/null || echo "æœªçŸ¥")
        echo "  - seetacloud-v802: ${percentage}% è®¡ç®—è´Ÿè½½"
    fi
    
    echo ""
    echo "ğŸ¯ **é…ç½®å»ºè®®**:"
    if [ "$v800_gpus" -eq 2 ]; then
        echo "  ğŸ’¡ å»ºè®®v800å‡çº§åˆ°3å¡ä»¥è·å¾—æ›´å¥½çš„è´Ÿè½½å‡è¡¡"
        echo "     - å½“å‰: 2+4+4=10 GPU (20%ä¸å‡è¡¡)"
        echo "     - å»ºè®®: 3+4+4=11 GPU (9.1%ä¸å‡è¡¡)"
        echo "     - æ€§èƒ½æå‡: ~10%"
    elif [ "$v800_gpus" -eq 3 ]; then
        echo "  âœ… å½“å‰3å¡é…ç½®å·²ç»å¾ˆå¥½ï¼è´Ÿè½½ç›¸å¯¹å‡è¡¡"
    fi
    
    echo ""
    echo "ğŸ”§ **é›¶æ ·æœ¬åˆ†ç±»æµ‹è¯•å»ºè®®**:"
    echo "  - å•æœåŠ¡å™¨æµ‹è¯•: ./run_zeroshot_classification.sh"
    echo "  - åˆ†å¸ƒå¼æµ‹è¯•: ./distributed_coordinator.sh"
    echo "  - æ€§èƒ½ç›‘æ§: watch -n 1 'nvidia-smi'"
    
else
    echo -e "${RED}âŒ æ²¡æœ‰å¯ç”¨çš„GPUèŠ‚ç‚¹${NC}"
fi

echo ""
echo "ğŸ“ é…ç½®å·²ä¿å­˜è‡³: dynamic_gpu_config.env"
echo "ğŸ“š å»ºè®®åˆ é™¤æ—§çš„ check_gpu_setup.shï¼Œä½¿ç”¨æ­¤å¢å¼ºç‰ˆè„šæœ¬" 